{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db59592c-c4f5-480d-b790-21900bbe88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " # reduced display precision on numpy arrays\n",
    "np.set_printoptions(precision=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23eab8cf-83d3-46ac-b054-947dd6010a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n ; # of features\n",
    "# x_train contain : house size, # bedroom, # floors, age \n",
    "X_train = np.array([[2104, 5, 1, 45], \n",
    "                    [1416, 3, 2, 40], \n",
    "                    [852, 2, 1, 35]])\n",
    "# y_train contains : price \n",
    "y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b316d8-a5cf-49ec-af38-7566524f92d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "\n",
      "X Shape: (3, 4)\n",
      "\n",
      "X Type:<class 'numpy.ndarray'>)\n",
      "\n",
      "[460 232 178]\n",
      "\n",
      "y Shape: (3,)\n",
      "\n",
      "y Type:<class 'numpy.ndarray'>)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(f\"\\nX Shape: {X_train.shape}\\n\")\n",
    "print(f\"X Type:{type(X_train)})\\n\")\n",
    "\n",
    "print(y_train)\n",
    "print(f\"\\ny Shape: {y_train.shape}\\n\")\n",
    "print(f\"y Type:{type(y_train)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55776599-14de-4d56-97f2-d799b1204806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,)\n",
      "\n",
      "b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# our initial choices of w & b \n",
    "\n",
    "#bias\n",
    "b_init = 785.1811367994083\n",
    "\n",
    "#weights\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "\n",
    "print(f\"w_init shape: {w_init.shape}\\n\")\n",
    "print(f\"b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea82d7-a8df-4f34-a75c-04038138a8b3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f8014-ceac-4755-8073-a4cbd054787d",
   "metadata": {},
   "source": [
    "## computing dot product using a loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a0cdcc-676b-474e-9a97-31521564bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_loop(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters    \n",
    "      b (scalar):  model parameter     \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    # n is # of features\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    p = 0\n",
    "\n",
    "    # performing dot product using for loop \n",
    "    for i in range(n): \n",
    "        p +=  x[i] * w[i]       \n",
    "\n",
    "    # adding b in the end \n",
    "    p = p + b                \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56af80e2-a8d0-4b5a-8239-ea81a4e7f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_vec value: [2104    5    1   45]\n",
      "x_vec shape (4,)\n",
      "\n",
      "prediction: 459.9999976194083\n",
      "f_wb shape ()\n"
     ]
    }
   ],
   "source": [
    "# getting first row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"\\nx_vec value: {x_vec}\")\n",
    "print(f\"x_vec shape {x_vec.shape}\\n\")\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"prediction: {f_wb}\")\n",
    "print(f\"f_wb shape {f_wb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf7b9f-4615-45e2-9c11-b32b9a709a6c",
   "metadata": {},
   "source": [
    "## computing dot product using np.dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a542061b-3916-470e-9744-b5bc71cfc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing as above, using np.dot instead\n",
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7465a87a-978c-40dd-93c1-a5dcecdcef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_vec value: [2104    5    1   45]\n",
      "x_vec shape (4,)\n",
      "\n",
      "prediction: 459.9999976194083\n",
      "f_wb shape ()\n"
     ]
    }
   ],
   "source": [
    "# getting first row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"\\nx_vec value: {x_vec}\")\n",
    "print(f\"x_vec shape {x_vec.shape}\\n\")\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"prediction: {f_wb}\")\n",
    "print(f\"f_wb shape {f_wb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22813d-d9a5-4d06-8b60-21416ca5db45",
   "metadata": {},
   "source": [
    "\n",
    "## Compute Cost With Multiple Variables\n",
    "cost function with multiple variables $J(\\mathbf{w},b)$ :\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "$\\mathbf{w}$ and $\\mathbf{x}^{(i)}$ are vectors rather than scalars supporting multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de7fc34b-5246-410b-bc68-9bd4911e98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    # size of first element \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    cost = 0.0\n",
    "    \n",
    "    for i in range(m):   \n",
    "        \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        \n",
    "        cost += (f_wb_i - y[i])**2             #scalar\n",
    "        \n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374a7445-41b1-4d43-8ec0-55fd01ac47d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : 1.5578904428966628e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our chosen optimal parameters. \n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c5ff3-2c1b-4e81-aa9d-0289e51fc213",
   "metadata": {},
   "source": [
    "\n",
    "## Gradient Descent With Multiple Variables\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc6f64e4-78cf-49b8-b9c5-f950b30f0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] += err * X[i, j] \n",
    "            \n",
    "        dj_db += err        \n",
    "        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2a7252e-2251-47a2-a27f-dbc5a578fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251501955248e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917d6f3c-8fb0-43b7-97d8-3c81c575fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    \n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    \n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1b0330f-46a5-4b63-8220-27d626f2fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  2529.46   \n",
      "Iteration  100: Cost   695.99   \n",
      "Iteration  200: Cost   694.92   \n",
      "Iteration  300: Cost   693.86   \n",
      "Iteration  400: Cost   692.81   \n",
      "Iteration  500: Cost   691.77   \n",
      "Iteration  600: Cost   690.73   \n",
      "Iteration  700: Cost   689.71   \n",
      "Iteration  800: Cost   688.70   \n",
      "Iteration  900: Cost   687.69   \n",
      "b,w found by gradient descent: -0.00,[ 0.2   0.   -0.01 -0.07] \n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5a730a7-dec1-4b17-9b31-0ced8baac531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 426.19, target value: 460\n",
      "prediction: 286.17, target value: 232\n",
      "prediction: 171.47, target value: 178\n"
     ]
    }
   ],
   "source": [
    "m,_ = X_train.shape\n",
    "\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344974d5-100b-434b-a7b3-b5edb1404023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
